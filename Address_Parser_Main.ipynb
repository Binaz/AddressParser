{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Binaz/AddressParser/blob/main/Address_Parser_Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Address Parser using BERT-based NER\n",
        "\n",
        "This notebook fine-tunes a **Transformer model** to extract structured address information such as street number, street name, city, state, and postal code from unstructured text.  \n",
        "\n",
        "We use **Hugging Face Transformers**, **datasets**, and **seqeval** to build and evaluate the model.  \n",
        "All training is done in **Google Colab** using a dataset stored in Google Drive.\n",
        "The synthetic dataset was created which includes variety of addresses, in different formats and different abbreviations."
      ],
      "metadata": {
        "id": "2XKvry79sbyy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa774KXP2r1y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup: Mount Google Drive and install required libraries\n",
        "We mount Google Drive to access the dataset stored in the user's Drive and install the required Python packages such as `transformers`, `datasets`, and `evaluate`.\n"
      ],
      "metadata": {
        "id": "2HPXAv32tMno"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NX1wpA4aX0D5"
      },
      "outputs": [],
      "source": [
        "!pip install evaluate transformers==4.49.0\n",
        "!pip install datasets==2.14.6\n",
        "!pip install DatasetDict"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Dataset from Google Drive\n",
        "We specify the CSV path using `os.path` and load it with the `datasets` library.  \n",
        "The synthetic dataset was created using different address structures.\n",
        "This dataset contains tokenized addresses with corresponding NER tags.\n"
      ],
      "metadata": {
        "id": "lqRo1ZqvtYBr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qVWG7zyoZVlh"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "\n",
        "# Use os.path to handle file paths\n",
        "csv_path = os.path.join(\"/content/drive\", \"My Drive\", \"Colab Notebooks\", \"Version 3\",\"Training_Dataset_ForModelVersion_3_2.csv\")\n",
        "\n",
        "# Load the dataset using the correct path\n",
        "\n",
        "address_ner_dataset = load_dataset('csv',data_files=csv_path )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning: Convert stringified lists into Python lists\n",
        "The dataset columns `tokens` and `ner_tags` are stored as strings.  \n",
        "We convert them back into Python lists for proper token alignment and processing.\n"
      ],
      "metadata": {
        "id": "7IDAAoXYvsmD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCcNGRdnaRrv"
      },
      "outputs": [],
      "source": [
        "# Fix: Convert stringified lists to actual lists if needed\n",
        "def convert_str_lists(example):\n",
        "    if isinstance(example[\"tokens\"], str):\n",
        "        example[\"tokens\"] = eval(example[\"tokens\"])\n",
        "    if isinstance(example[\"ner_tags\"], str):\n",
        "        example[\"ner_tags\"] = eval(example[\"ner_tags\"])\n",
        "    return example\n",
        "\n",
        "address_ner_dataset = address_ner_dataset.map(convert_str_lists)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Split: Train, Validation, Test\n",
        "We split the dataset into training (80%), validation (10%), and test (10%) sets using Hugging Face’s built-in `train_test_split()` method.\n"
      ],
      "metadata": {
        "id": "yaKw1-nQv0qX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94UmuPdEZXjQ"
      },
      "outputs": [],
      "source": [
        "## This function randomly selects / splits records for training , validation and test dataset.\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "# First split into train and temp (this will be used for validation + test)\n",
        "train_dataset, temp_dataset = address_ner_dataset[\"train\"].train_test_split(test_size=0.2).values()\n",
        "\n",
        "# Then split temp into validation and test\n",
        "validation_dataset, test_dataset = temp_dataset.train_test_split(test_size=0.5).values()\n",
        "\n",
        "# Now you have `train_dataset`, `validation_dataset`, and `test_dataset`\n",
        "\n",
        "# If needed, you can print to confirm the splits\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(validation_dataset)}\")\n",
        "print(f\"Test set size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a DatasetDict for Training\n",
        "We organize all splits into a single `DatasetDict` object for convenience when passing data to the model.\n"
      ],
      "metadata": {
        "id": "p2uvJmCwwBVZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGTbdNsC9yl7"
      },
      "outputs": [],
      "source": [
        "# The first 80% goes to training (by order),\n",
        "# The last 20% is split evenly into validation and test (10% each), randomly.\n",
        "\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Access the actual dataset from the DatasetDict\n",
        "full_dataset = address_ner_dataset[\"train\"]\n",
        "\n",
        "# Define split percentage\n",
        "train_split_percent = 0.8\n",
        "total_samples = len(full_dataset)\n",
        "train_end = int(total_samples * train_split_percent)\n",
        "\n",
        "# Deterministic slicing\n",
        "train_dataset = full_dataset.select(range(train_end))\n",
        "remaining_dataset = full_dataset.select(range(train_end, total_samples))\n",
        "\n",
        "# Now split the remaining into validation and test\n",
        "val_test_split = remaining_dataset.train_test_split(test_size=0.5, seed=42)\n",
        "validation_dataset = val_test_split['train']\n",
        "test_dataset = val_test_split['test']\n",
        "\n",
        "# Optional: Group into a DatasetDict\n",
        "dataset_dict = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': validation_dataset,\n",
        "    'test': test_dataset\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "iboQri5WZZgA"
      },
      "outputs": [],
      "source": [
        "print(train_dataset.features)\n",
        "print(train_dataset[0:50])\n",
        "print(validation_dataset[0:50])\n",
        "print(test_dataset[0:50])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Entity Labels and Label Mapping\n",
        "We define custom entity labels representing components of an address (e.g., `B-STREET`, `I-CITY`, etc.) and create a dictionary mapping label names to integer IDs."
      ],
      "metadata": {
        "id": "Mn3Ukr5NwRr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Ps6SXHM0UR-E"
      },
      "outputs": [],
      "source": [
        "# Accessing the label names from the 'ner_tags' feature.   This is used\n",
        "label_names = ['O','B-NAME','I-NAME','B-STREET_NUM','I-STREET_NUM','B-STREET','I-STREET','B-UNIT','I-UNIT','B-CITY','I-CITY','B-STATE','I-STATE','B-POSTAL','I-POSTAL'] #address_ner_dataset['train'][0]['ner_tags'] #tokenized_datasets['train'].features['ner_tags']\n",
        "\n",
        "#label_encoding_dict = {'O':0,'B-NAME':1,'I-NAME':2,'B-STREET_NUMBER':3,'I-STREET_NUMBER':4,'B-STREET_NAME':5,'I-STREET_NAME':6,'B-UNIT_NUMBER':7,'I-UNIT_NUMBER':8,'B-UNIT_DESIGNATOR':9,'I-UNIT_DESIGNATOR':10,'B-CITY':11,'I-CITY':12,'B-STATE_ABBREVIATION':13,'I-STATE_ABBREVIATION':14,'B-PLUS_4':15,'I-PLUS_4':16,'B-STATE_NAME':17,'I-STATE_NAME':18,'B-POSTAL_CODE':19,'I-POSTAL_CODE':20,'B-TRACKING_NUMBER':21,'I-TRACKING_NUMBER':22}\n",
        "label_encoding_dict = {\n",
        "    \"O\": 0,\n",
        "    \"B-NAME\": 1,\n",
        "    \"I-NAME\": 2,\n",
        "    \"B-STREET_NUM\": 3,\n",
        "    \"I-STREET_NUM\": 4,\n",
        "    \"B-STREET\": 5,\n",
        "    \"I-STREET\": 6,\n",
        "    \"B-UNIT\": 7,\n",
        "    \"I-UNIT\": 8,\n",
        "    \"B-CITY\": 9,\n",
        "    \"I-CITY\": 10,\n",
        "    \"B-STATE\": 11,\n",
        "    \"I-STATE\": 12,\n",
        "    \"B-POSTAL\": 13,\n",
        "    \"I-POSTAL\": 14\n",
        "}\n",
        "label_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3gp3ANfKZj4Y"
      },
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization & Label Alignment\n",
        "This function tokenizes input tokens and aligns their corresponding NER tags.  \n",
        "It ensures labels correspond correctly to subword tokens generated by BERT.\n"
      ],
      "metadata": {
        "id": "i-YAlHPywaD5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkYgscrIUY1a"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(batch):\n",
        "    label_all_tokens = True\n",
        "    #tokenized_inputs = tokenizer(list(batch[\"tokens\"]), truncation=True, is_split_into_words=True, padding='max_length')\n",
        "    tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True, padding='max_length') #return_offsets_mapping=True\n",
        "\n",
        "     # Define a mapping from beginning (B-) labels to inside (I-) labels\n",
        "    begin2inside = {\n",
        "        \"B-NAME\": \"I-NAME\",\n",
        "        \"B-STREET_NUM\": \"I-STREET_NUM\",\n",
        "        \"B-STREET\": \"I-STREET\",\n",
        "        \"B-UNIT\": \"I-UNIT\",\n",
        "        \"B-CITY\" : \"I-CITY\",\n",
        "        \"B-STATE\" : \"I-STATE\",\n",
        "        \"B-POSTAL\" : \"I-POSTAL\",\n",
        "    }\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(batch[f\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
        "            else:\n",
        "                labelId = (label_encoding_dict[label[word_idx]])\n",
        "                # Change B- to I- if the previous word is the same\n",
        "                if label[word_idx] in begin2inside:\n",
        "                    labelId = (label_encoding_dict[begin2inside[label[word_idx]]])  # Map B- to I-\n",
        "                label_ids.append(labelId if label_all_tokens else -100)\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Tokenizer\n",
        "We use the pretrained `bert-base-NER-uncased` tokenizer for tokenizing address tokens.  \n",
        "This ensures consistency with the BERT model vocabulary.\n"
      ],
      "metadata": {
        "id": "_CPKWlIzweDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ydO-EiNiZq8Q"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the checkpoint you want to use for the tokenizer.\n",
        "checkpoint = 'dslim/bert-base-NER-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,num_labels=len(label_names),is_split_into_words = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test the Tokenization and Label Alignment Function\n",
        "We apply the function on a single example to verify label alignment correctness.  \n",
        "This step helps ensure that labels and tokens match as expected.\n"
      ],
      "metadata": {
        "id": "l-mqCx-twn6b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2O0m6t9H5Hm6"
      },
      "outputs": [],
      "source": [
        "## The follwoing code is to test if tokenize_and_align_labels is working correctly\n",
        "\n",
        "# Example input (word-level tokens with labels)\n",
        "#test_batch = {\n",
        "#    \"tokens\": [[\"19\", \"Waldo\", \"AvenuewESTeAST\",\"East\", \"BelfastCORNILANA\", \",\", \"ME\", \"04915\" ,\"Consolidated\", \"Communications\"]],\n",
        "#    \"ner_tags\": [[\n",
        "#        \"S-STREET_NUM\", \"B-STREET\", \"I-STREET\", \"E-STREET\", \"S-CITY\", \"O\", \"S-STATE\", \"S-POSTAL\",\"O\",\"O\"\n",
        "#    ]]\n",
        "#}\n",
        "\n",
        "# Take a single example from your actual dataset\n",
        "test_example = train_dataset[3]\n",
        "\n",
        "\n",
        "# Wrap it in a batch format expected by the function\n",
        "test_batch = {\n",
        "    \"tokens\": [test_example[\"tokens\"]],\n",
        "    \"ner_tags\": [test_example[\"ner_tags\"]]\n",
        "}\n",
        "\n",
        "#label_encoding_dict = {'O':0,'B-NAME':1,'I-NAME':2,'B-STREET_NUMBER':3,'I-STREET_NUMBER':4,'B-STREET_NAME':5,'I-STREET_NAME':6,'B-UNIT_NUMBER':7,'I-UNIT_NUMBER':8,'B-UNIT_DESIGNATOR':9,'I-UNIT_DESIGNATOR':10,'B-CITY':11,'I-CITY':12,'B-STATE_ABBREVIATION':13,'I-STATE_ABBREVIATION':14,'B-PLUS_4':15,'I-PLUS_4':16,'B-STATE_NAME':17,'I-STATE_NAME':18,'B-POSTAL_CODE':19,'I-POSTAL_CODE':20,'B-TRACKING_NUMBER':21,'I-TRACKING_NUMBER':22}\n",
        "label_encoding_dict = {\n",
        "    \"O\": 0,\n",
        "    \"B-NAME\": 1,\n",
        "    \"I-NAME\": 2,\n",
        "    \"B-STREET_NUM\": 3,\n",
        "    \"I-STREET_NUM\": 4,\n",
        "    \"B-STREET\": 5,\n",
        "    \"I-STREET\": 6,\n",
        "    \"B-UNIT\": 7,\n",
        "    \"I-UNIT\": 8,\n",
        "    \"B-CITY\": 9,\n",
        "    \"I-CITY\": 10,\n",
        "    \"B-STATE\": 11,\n",
        "    \"I-STATE\": 12,\n",
        "    \"B-POSTAL\": 13,\n",
        "    \"I-POSTAL\": 14\n",
        "}\n",
        "# Reverse mapping\n",
        "id2label = {v: k for k, v in label_encoding_dict.items()}\n",
        "\n",
        "# Use your tokenize_and_align_labels function\n",
        "# Apply the function\n",
        "encoded = tokenize_and_align_labels(test_batch)\n",
        "\n",
        "# Visualize token-label mapping\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"][0])\n",
        "labels = encoded[\"labels\"][0]\n",
        "\n",
        "print(\"Token\\t\\tLabel\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for token, label_id in zip(tokens, labels):\n",
        "    if label_id == -100:\n",
        "        print(f\"{token:10s}\\tIGNORED\")\n",
        "    else:\n",
        "        print(f\"{token:10s}\\t{id2label[label_id]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-_llBa_ZwSg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Tokenize the first training example from the dataset\n",
        "token = tokenizer(train_dataset[0]['tokens'],is_split_into_words = True)  ##, return_offsets_mapping=True\n",
        "\n",
        "# Print the tokenizer object, the tokenized tokens, and the word IDs\n",
        "print(token, '\\n--------------------------------------------------------------------------------------\\n',\n",
        "      token.tokens(),'\\n--------------------------------------------------------------------------------------\\n',\n",
        "      token.word_ids(),'\\n--------------------------------------------------------------------------------------\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply Tokenization to All Dataset Splits\n",
        "We apply the `tokenize_and_align_labels()` function to the entire train, validation, and test datasets.\n"
      ],
      "metadata": {
        "id": "Un_sZKGmwxnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VQMWwJbzZ89w"
      },
      "outputs": [],
      "source": [
        "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=train_dataset.column_names)\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=test_dataset.column_names)\n",
        "tokenized_validation_dataset = validation_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=validation_dataset.column_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Data Collator for Token Classification\n",
        "The `DataCollatorForTokenClassification` dynamically pads input sequences and labels during training.\n"
      ],
      "metadata": {
        "id": "k07tjsPlw1xh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "qkkUsotaaQTH"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# Create a DataCollatorForTokenClassification object\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "print(tokenized_train_dataset)\n",
        "# Testing data using the data collator\n",
        "batch = data_collator([tokenized_train_dataset[i] for i in range(1)])\n",
        "\n",
        "# Display the resulting batch\n",
        "batch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Evaluation Metric\n",
        "We install and import the `seqeval` metric via Hugging Face’s `evaluate` library to compute precision, recall, F1, and accuracy."
      ],
      "metadata": {
        "id": "7pvOSBbZMYIG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "snwB5LmgaWWw"
      },
      "outputs": [],
      "source": [
        "# Install the seqeval library for evaluating sequence tasks\n",
        "!pip install seqeval ;\n",
        "!pip install evaluate ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JVDIXnJaZvv"
      },
      "outputs": [],
      "source": [
        "# Import the seqeval metric from Hugging Face's datasets library\n",
        "import evaluate\n",
        "\n",
        "# Load the seqeval metric which can evaluate NER and other sequence tasks\n",
        "metric = evaluate.load(\"seqeval\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compute Evaluation Metrics\n",
        "This function calculates precision, recall, F1-score, and accuracy from the model’s predictions and true labels.\n"
      ],
      "metadata": {
        "id": "2LvHxn65xAuu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6t_wnTX_aaQn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Function to compute evaluation metrics from model logits and true labels\n",
        "def compute_metrics(logits_and_labels):\n",
        "\n",
        "  # Unpack the logits and labels\n",
        "  logits, labels = logits_and_labels\n",
        "\n",
        "  # Get predictions from the logits\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  # Remove ignored index (special tokens)\n",
        "  str_labels = [\n",
        "    [label_names[t] for t in label if t!=-100] for label in labels\n",
        "  ]\n",
        "\n",
        "  str_preds = [\n",
        "    [label_names[p] for (p, t) in zip(prediction, label) if t != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "  ]\n",
        "\n",
        "  # Compute metrics\n",
        "  results = metric.compute(predictions=str_preds, references=str_labels)\n",
        "\n",
        "  # Extract key metrics\n",
        "  return {\n",
        "    \"precision\": results[\"overall_precision\"],\n",
        "    \"recall\": results[\"overall_recall\"],\n",
        "    \"f1\": results[\"overall_f1\"],\n",
        "    \"accuracy\": results[\"overall_accuracy\"]\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGNSPMJOacnH"
      },
      "outputs": [],
      "source": [
        "# Create mapping from label ID to label string name\n",
        "id2label = {k: v for k, v in enumerate(label_names)}\n",
        "\n",
        "# Create reverse mapping from label name to label ID\n",
        "label2id = {v: k for k, v in enumerate(label_names)}\n",
        "\n",
        "print(id2label , '\\n--------------------\\n' , label2id)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pretrained Model for Token Classification\n",
        "We load the `dslim/bert-base-NER-uncased` model with the correct number of labels and mappings (`id2label`, `label2id`).\n"
      ],
      "metadata": {
        "id": "x1QnQYPpxJD7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KsyWHrD8aemP"
      },
      "outputs": [],
      "source": [
        "# Load pretrained token classification model from Transformers\n",
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# Initialize model object with pretrained weights\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "  checkpoint,\n",
        "  num_labels=len(label_names),\n",
        "  # Pass in label mappings\n",
        "  id2label=id2label,\n",
        "  label2id=label2id,\n",
        "  ignore_mismatched_sizes=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Setup and Save Fine-tuned Model\n",
        "We configure `TrainingArguments`, optimizer, scheduler, and callbacks for fine-tuning the model.\n",
        "After training completes, we save the fine-tuned model to Google Drive for reuse or deployment.\n"
      ],
      "metadata": {
        "id": "LNB0JMHTxRMc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofzjOqt5CGet"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    Trainer, TrainingArguments, EarlyStoppingCallback,\n",
        "    AutoModelForTokenClassification, get_scheduler, AdamW\n",
        ")\n",
        "\n",
        "# Create mapping from label ID to string and vice versa\n",
        "id2label = {k: v for k, v in enumerate(label_names)}\n",
        "label2id = {v: k for k, v in enumerate(label_names)}\n",
        "\n",
        "# Load model with label mapping\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(label_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"address_parser_fine_tuned_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,               #Lower the better, can range from 1e-5 (i.e. 0.00001 small) to 2e-5(i.e. 0.00002 large)\n",
        "    per_device_train_batch_size=32,   # For less number of training records (eg. <5k), lesser the batch size the better like 16. But for greater training dataset batch size should be more like 32\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=15,\n",
        "    weight_decay=0.01,\n",
        "    gradient_accumulation_steps=1,\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",  # Must match the key returned by compute_metrics\n",
        "    report_to=\"none\",\n",
        "    fp16=True                    # Enable mixed-precision training\n",
        ")\n",
        "\n",
        "# Optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Scheduler setup\n",
        "num_training_steps = (\n",
        "    (len(tokenized_train_dataset) // training_args.per_device_train_batch_size)\n",
        "    * training_args.num_train_epochs\n",
        ")\n",
        "\n",
        "# Compute warmup steps as 10% of total steps\n",
        "num_warmup_steps = int(0.1 * num_training_steps)\n",
        "\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=3)  # Early Stopping after 3 epochs\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset.shuffle(seed=42).select(range(168456)),\n",
        "    eval_dataset=tokenized_test_dataset.shuffle(seed=42).select(range(21056)),\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator,\n",
        "    optimizers=(optimizer, lr_scheduler),  # Correct way to use scheduler\n",
        "    callbacks=[early_stopping_callback],\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "path = F\"/content/drive/My Drive/Colab Notebooks/Version 3/Trainer_Model_Version_3_2/\"\n",
        "trainer.save_model(path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Model for Inference\n",
        "We load the trained model using `pipeline()` to perform token classification on new address strings.  \n",
        "This allows easy testing and demonstration of real-world performance.\n"
      ],
      "metadata": {
        "id": "KFcdfg9rmPGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nerTrainer_new = pipeline(\n",
        "    'token-classification',\n",
        "    '/content/drive/My Drive/Colab Notebooks/Version 3/Trainer_Model_Version_3_2/',\n",
        "    tokenizer=tokenizer,\n",
        "    grouped_entities=True,\n",
        "    aggregation_strategy = 'simple' ,\n",
        "    device = -1   # device = 0 for gpu & device = -1 for cpu\n",
        ")"
      ],
      "metadata": {
        "id": "Qpf7ackP-8NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output/ Inference Result\n",
        "\n",
        "Below are sample address strings and the structured address components extracted by the fine-tuned **Address Parser** model.\n",
        "\n",
        "Each address is converted into a set of `(value, label)` pairs for easy downstream use.\n",
        "\n",
        "---\n",
        "# Address Parsing Results\n",
        "\n",
        "## 1. Address: 754-782 BROADWAY, 23, CHULA VISTA CA 919105372\n",
        "\n",
        "- **STREET_NUM**: `754 - 782`, Score: `1.0`\n",
        "- **STREET**: `BROADWAY`, Score: `1.0`\n",
        "- **CITY**: `CHULA VISTA`, Score: `1.0`\n",
        "- **STATE**: `CA`, Score: `1.0`\n",
        "- **POSTAL**: `919105372`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Address: Kashyap Property-1284 Leland Road-Manassas-VA-20111-Prince William County\n",
        "\n",
        "- **NAME**: `kashyap property`, Score: `1.0`\n",
        "- **STREET_NUM**: `1284`, Score: `1.0`\n",
        "- **STREET**: `LELAND ROAD`, Score: `1.0`\n",
        "- **CITY**: `MANASSAS`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `20111`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Address: The address of the suspected auto service station is 108 Harrison Street Southeast, Leesburg, VA 20198.\n",
        "\n",
        "- **NAME**: `suspected auto service station`, Score: `0.9999`\n",
        "- **STREET_NUM**: `108`, Score: `1.0`\n",
        "- **STREET**: `HARRISON STREET SOUTHEAST`, Score: `1.0`\n",
        "- **CITY**: `LEESBURG`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `20198`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Address: 7890 Old Mill Road, Richmond, VA 23225\n",
        "\n",
        "- **STREET_NUM**: `7890`, Score: `1.0`\n",
        "- **STREET**: `OLD MILL ROAD`, Score: `1.0`\n",
        "- **CITY**: `RICHMOND`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `23225`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Address: Exit 54 on I-95 South near Fayetteville, NC\n",
        "\n",
        "- **STREET**: `EXIT 54 ON I-95 SOUTH`, Score: `0.8667`\n",
        "- **CITY**: `FAYETTEVILLE`, Score: `1.0`\n",
        "- **STATE**: `NC`, Score: `0.9998`\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Address: Various locations throughout the Upper Peninsula, corporate address located at 920 10th Avenue North, varies, MI, 95855-0000, US\n",
        "\n",
        "- **STREET_NUM**: `920`, Score: `1.0`\n",
        "- **STREET**: `10TH AVENUE NORTH`, Score: `1.0`\n",
        "- **CITY**: `VARIES`, Score: `1.0`\n",
        "- **STATE**: `MI`, Score: `1.0`\n",
        "- **POSTAL**: `95855-0000`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 7. Address: 1228-1290 Middletown & Warwick Road, Middletown, DE 19709 US\n",
        "\n",
        "- **STREET_NUM**: `1228 - 1290`, Score: `1.0`\n",
        "- **STREET**: `MIDDLETOWN & WARWICK ROAD`, Score: `1.0`\n",
        "- **CITY**: `MIDDLETOWN`, Score: `1.0`\n",
        "- **STATE**: `DE`, Score: `1.0`\n",
        "- **POSTAL**: `19709`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 8. Address: Express Trucking Co-700 1st St-Harrison-VA-07029-Frederick County\n",
        "\n",
        "- **NAME**: `TRUCKING CO`, Score: `0.9005`\n",
        "- **STREET_NUM**: `700`, Score: `1.0`\n",
        "- **STREET**: `1ST ST`, Score: `1.0`\n",
        "- **CITY**: `HARRISON`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `07029`, Score: `1.0`\n",
        "- **CITY**: `FREDERICK COUNTY`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 9. Address: 4200 Summit Bridge Road, Summit Airport, Middletown, DE 19709 US\n",
        "\n",
        "- **STREET_NUM**: `4200`, Score: `1.0`\n",
        "- **STREET**: `SUMMIT BRIDGE ROAD`, Score: `1.0`\n",
        "- **CITY**: `SUMMIT AIRPORT`, Score: `0.9954`\n",
        "- **CITY**: `MIDDLETOWN`, Score: `1.0`\n",
        "- **STATE**: `DE`, Score: `1.0`\n",
        "- **POSTAL**: `19709`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 10. Address: The actual compost site is located across the street from a community member home: 17397 Count Turf Place.  However, the name of the business, Clairvoux LLC and address is: 40730 Farm Market Road, Leesburg 20176. The compost site is located on land they own in the community.  Route 7 West to Farm Market Road, turn right onto Alysheba Drive, left onto Count Turf.  Compost site is on right about 100 feet.\n",
        "\n",
        "- **NAME**: `ACTUAL COMPOST SITE`, Score: `0.9638`\n",
        "- **STREET_NUM**: `17397`, Score: `1.0`\n",
        "- **STREET**: `COUNT TURF PLACE`, Score: `1.0`\n",
        "- **NAME**: `CLAIRVOUX LLC`, Score: `0.9998`\n",
        "- **STREET_NUM**: `40730`, Score: `1.0`\n",
        "- **STREET**: `FARM MARKET ROAD`, Score: `1.0`\n",
        "- **CITY**: `LEESBURG`, Score: `1.0`\n",
        "- **POSTAL**: `20176`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 11. Address: Capitol Fiber, Inc - Recycling Center-6610 Electronic Drive-Springfield-VA-22151-Fairfax County\n",
        "\n",
        "- **NAME**: `CAPITOL FIBER, INC`, Score: `0.9999`\n",
        "- **STREET_NUM**: `6610`, Score: `1.0`\n",
        "- **STREET**: `ELECTRONIC DRIVE`, Score: `1.0`\n",
        "- **CITY**: `SPRINGFIELD`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `22151`, Score: `1.0`\n",
        "- **CITY**: `FAIRFAX COUNTY`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 12. Address: This incident took place at 980 Bayshore rd. Cape Charles, VA 23318\n",
        "\n",
        "- **STREET_NUM**: `980`, Score: `0.9999`\n",
        "- **STREET**: `BAYSHORE RD.`, Score: `0.9999`\n",
        "- **CITY**: `CAPE CHARLES`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `23318`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 13. Address: Oyster Farm at Kings Creek 500 Marina Village Cir Cape Charles, VA 23310\n",
        "\n",
        "- **NAME**: `OYSTER FARM AT KINGS`, Score: `0.9892`\n",
        "- **STREET_NUM**: `500`, Score: `1.0`\n",
        "- **STREET**: `MARINA VILLAGE CIR`, Score: `1.0`\n",
        "- **CITY**: `CAPE CHARLES`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `23310`, Score: `1.0`\n",
        "\n",
        "---\n",
        "\n",
        "## 14. Address: On North Curry St. between County St and Sewell Ave. Directly across the Street from 33 N.Curry St, Hampton,Va 23663-5858\n",
        "\n",
        "- **STREET**: `COUNTY ST AND SEWELL AVE`, Score: `0.9999`\n",
        "- **STREET_NUM**: `33`, Score: `1.0`\n",
        "- **STREET**: `N. CURRY ST`, Score: `1.0`\n",
        "- **CITY**: `HAMPTON`, Score: `1.0`\n",
        "- **STATE**: `VA`, Score: `1.0`\n",
        "- **POSTAL**: `23663-5858`, Score: `1.0`\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "zpfBmoFcNP1O"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DX4n0z2d_Mig"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}