{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwB9NtkMpkdi"
      },
      "source": [
        "# Using pretrained models (PyTorch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H62mB3jpkdk"
      },
      "source": [
        "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vIipGxxDsk9U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hgYpDEzJpkdk",
        "outputId": "27210a6e-8738-462e-db02-51c37ec12f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets evaluate transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "crrXt7Bdpkdl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8829981-bfa5-474f-e644-7bac78771357"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "address_ner_dataset = load_dataset(\"TrevorJS/synth-addresses-ner-mk3\")\n",
        "\n",
        "#from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "#from transformers import pipeline\n",
        "\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
        "\n",
        "#def tokenize_function(examples):\n",
        "#    return tokenizer(examples[\"ocr_text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "#tokenized_datasets = address_ner_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "#small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(100))\n",
        "#small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(address_ner_dataset['train'].features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2scZYvhbQH1",
        "outputId": "37d6e49e-8be2-40b9-c3c6-50d82e828545",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': Value(dtype='string', id=None), 'state_name': Value(dtype='string', id=None), 'state_abbreviation': Value(dtype='string', id=None), 'postal_code': Value(dtype='string', id=None), 'city': Value(dtype='string', id=None), 'street_number': Value(dtype='string', id=None), 'street_name': Value(dtype='string', id=None), 'unit_number': Value(dtype='string', id=None), 'unit_designator': Value(dtype='string', id=None), 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ocr_text': Value(dtype='string', id=None), 'type': Value(dtype='string', id=None), 'tracking_number': Value(dtype='string', id=None), 'plus_4': Value(dtype='string', id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the label names from the 'ner_tags' feature.\n",
        "label_names = ['O','B-NAME','I-NAME','B-STREET_NUMBER','I-STREET_NUMBER','B-STREET_NAME','I-STREET_NAME','B-UNIT_NUMBER','I-UNIT_NUMBER','B-UNIT_DESIGNATOR','I-UNIT_DESIGNATOR','B-CITY','I-CITY','B-STATE_ABBREVIATION','I-STATE_ABBREVIATION','B-PLUS_4','I-PLUS_4','B-STATE_NAME','I-STATE_NAME','B-POSTAL_CODE','I-POSTAL_CODE','B-TRACKING_NUMBER','I-TRACKING_NUMBER'] #address_ner_dataset['train'][0]['ner_tags'] #tokenized_datasets['train'].features['ner_tags']\n",
        "\n",
        "label_encoding_dict = {'O':0,'B-NAME':1,'I-NAME':2,'B-STREET_NUMBER':3,'I-STREET_NUMBER':4,'B-STREET_NAME':5,'I-STREET_NAME':6,'B-UNIT_NUMBER':7,'I-UNIT_NUMBER':8,'B-UNIT_DESIGNATOR':9,'I-UNIT_DESIGNATOR':10,'B-CITY':11,'I-CITY':12,'B-STATE_ABBREVIATION':13,'I-STATE_ABBREVIATION':14,'B-PLUS_4':15,'I-PLUS_4':16,'B-STATE_NAME':17,'I-STATE_NAME':18,'B-POSTAL_CODE':19,'I-POSTAL_CODE':20,'B-TRACKING_NUMBER':21,'I-TRACKING_NUMBER':22}\n",
        "\n",
        "label_names"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3ewC82-OC18",
        "outputId": "f4ca26bd-1b49-4ebc-b4bf-e8a6e1fa22dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O',\n",
              " 'B-NAME',\n",
              " 'I-NAME',\n",
              " 'B-STREET_NUMBER',\n",
              " 'I-STREET_NUMBER',\n",
              " 'B-STREET_NAME',\n",
              " 'I-STREET_NAME',\n",
              " 'B-UNIT_NUMBER',\n",
              " 'I-UNIT_NUMBER',\n",
              " 'B-UNIT_DESIGNATOR',\n",
              " 'I-UNIT_DESIGNATOR',\n",
              " 'B-CITY',\n",
              " 'I-CITY',\n",
              " 'B-STATE_ABBREVIATION',\n",
              " 'I-STATE_ABBREVIATION',\n",
              " 'B-PLUS_4',\n",
              " 'I-PLUS_4',\n",
              " 'B-STATE_NAME',\n",
              " 'I-STATE_NAME',\n",
              " 'B-POSTAL_CODE',\n",
              " 'I-POSTAL_CODE',\n",
              " 'B-TRACKING_NUMBER',\n",
              " 'I-TRACKING_NUMBER']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "address_ner_dataset['train'][0]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WZpK8J7xGLw",
        "outputId": "6d0c8147-2e24-43bc-f6ea-788872368e21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'name': 'Gemmi Batteen',\n",
              " 'state_name': 'Nebraska',\n",
              " 'state_abbreviation': 'NE',\n",
              " 'postal_code': '69351',\n",
              " 'city': 'Lakeside',\n",
              " 'street_number': '39',\n",
              " 'street_name': 'Tara Court',\n",
              " 'unit_number': None,\n",
              " 'unit_designator': None,\n",
              " 'tokens': ['Gemmi',\n",
              "  'Batteen',\n",
              "  '39',\n",
              "  'Tara',\n",
              "  'Court',\n",
              "  'Adult',\n",
              "  'Signature',\n",
              "  'Required',\n",
              "  'Lakeside',\n",
              "  ',',\n",
              "  'NE',\n",
              "  '69351',\n",
              "  '-',\n",
              "  '1146'],\n",
              " 'ner_tags': ['B-NAME',\n",
              "  'I-NAME',\n",
              "  'B-STREET_NUMBER',\n",
              "  'B-STREET_NAME',\n",
              "  'I-STREET_NAME',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-CITY',\n",
              "  'O',\n",
              "  'B-STATE_ABBREVIATION',\n",
              "  'B-POSTAL_CODE',\n",
              "  'O',\n",
              "  'B-PLUS_4'],\n",
              " 'ocr_text': 'Gemmi Batteen 39 Tara Court Adult Signature Required Lakeside , NE 69351-1146',\n",
              " 'type': 'individual',\n",
              " 'tracking_number': None,\n",
              " 'plus_4': '1146'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    label_all_tokens = True\n",
        "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True, padding='max_length')\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n"
      ],
      "metadata": {
        "id": "12HhpBpTuQT_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Define the checkpoint you want to use for the tokenizer.\n",
        "checkpoint = 'issifuamajeed/distilbert-base-uncased-finetuned-ner'     ## Intially used :  dslim/distilbert-NER  next trained on : dslim/bert-base-NER-uncased   - The RAM is less for this model\n",
        "\n",
        "# Create a tokenizer instance by loading the pre-trained checkpoint.\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint,num_labels=len(label_names))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "aCbiieBi8OfK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the first training example from the dataset\n",
        "token = tokenizer(address_ner_dataset['train'][0]['tokens'], is_split_into_words = True)\n",
        "\n",
        "# Print the tokenizer object, the tokenized tokens, and the word IDs\n",
        "print(token, '\\n--------------------------------------------------------------------------------------\\n',\n",
        "      token.tokens(),'\\n--------------------------------------------------------------------------------------\\n',\n",
        "      token.word_ids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ylfXPey08gmt",
        "outputId": "c758025f-1341-4f6b-c83c-7aab9a9295e0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 17070, 4328, 7151, 17389, 2078, 4464, 10225, 2457, 4639, 8085, 3223, 28701, 1010, 11265, 6353, 19481, 2487, 1011, 12457, 2575, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} \n",
            "--------------------------------------------------------------------------------------\n",
            " ['[CLS]', 'gem', '##mi', 'bat', '##tee', '##n', '39', 'tara', 'court', 'adult', 'signature', 'required', 'lakeside', ',', 'ne', '69', '##35', '##1', '-', '114', '##6', '[SEP]'] \n",
            "--------------------------------------------------------------------------------------\n",
            " [None, 0, 0, 1, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 13, None]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DO NOT USE\n",
        "\n",
        "def align_target(labels, word_ids):\n",
        "    # Define a mapping from beginning (B-) labels to inside (I-) labels\n",
        "    begin2inside = {\n",
        "        \"B-NAME\": \"I-NAME\",  # B-LOC -> I-LOC\n",
        "        \"B-STREET_NUMBER\": \"I-STREET_NUMBER\",  # B-MISC -> I-MISC\n",
        "        \"B-STREET_NAME\": \"I-STREET_NAME\",  # B-ORG -> I-ORG\n",
        "        \"B-UNIT_NUMBER\": \"I-UNIT_NUMBER\",    # B-PER -> I-PER\n",
        "        \"B-UNIT_DESIGNATOR\" : \"I-UNIT_DESIGNATOR\",\n",
        "        \"B-CITY\" : \" I-CITY\",\n",
        "        \"B-STATE_ABBREVIATION\" : \"I-STATE_ABBREVIATION\",\n",
        "        \"B-PLUS_4\" : \"I-PLUS_4\",\n",
        "        \"B-STATE_NAME\" : \"I-STATE_NAME\",\n",
        "        \"B-POSTAL_CODE\" : \"I-POSTAL_CODE\",\n",
        "        \"B-TRACKING_NUMBER\":\"I-TRACKING_NUMBER\"\n",
        "    }\n",
        "\n",
        "    # Initialize an empty list to store aligned labels and a variable to track the last word\n",
        "    align_labels = []\n",
        "    last_word = None\n",
        "\n",
        "    # Iterate through the word_ids\n",
        "    for word in word_ids:\n",
        "        if word is None:\n",
        "            label = -100  # Set label to -100 for None word_ids\n",
        "        elif word != last_word:\n",
        "            label = labels[word]  # Use the label corresponding to the current word_id\n",
        "        else:\n",
        "            label = labels[word]\n",
        "            # Change B- to I- if the previous word is the same\n",
        "            if label in begin2inside:\n",
        "                label = begin2inside[label]  # Map B- to I-\n",
        "\n",
        "        # Append the label to the align_labels list and update last_word\n",
        "        align_labels.append(label)\n",
        "        last_word = word\n",
        "\n",
        "    return align_labels"
      ],
      "metadata": {
        "id": "KRR9RZYh88CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DO NOT USE\n",
        "\n",
        "# Extract labels and word_ids\n",
        "labels = address_ner_dataset['train'][0]['ner_tags']\n",
        "word_ids = token.word_ids()\n",
        "\n",
        "# Use the align_target function to align labels\n",
        "aligned_target = align_target(labels, word_ids)\n",
        "\n",
        "# Print tokenized tokens, original labels, and aligned labels\n",
        "print(token.tokens(), '\\n--------------------------------------------------------------------------------------\\n',\n",
        "      labels, '\\n--------------------------------------------------------------------------------------\\n',\n",
        "      aligned_target)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKjiY9C65pTv",
        "outputId": "2a7e1871-3324-4148-df09-f80e98bbe890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'align_target' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8a3092be0656>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Use the align_target function to align labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0maligned_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Print tokenized tokens, original labels, and aligned labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'align_target' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DO NOT USE\n",
        "\n",
        "# Create a list of aligned labels using label names\n",
        "aligned_labels = aligned_target\n",
        "\n",
        "# Loop through tokens and aligned labels and print them\n",
        "for x, y in zip(token.tokens(), aligned_labels):\n",
        "    print(f\"{x}\\t{y}\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOYBqvws6vvZ",
        "outputId": "85124d69-63e6-4ab2-c1b3-02025ee85ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]\t-100\n",
            "G\tB-NAME\n",
            "##em\tI-NAME\n",
            "##mi\tI-NAME\n",
            "Bat\tI-NAME\n",
            "##teen\tI-NAME\n",
            "39\tB-STREET_NUMBER\n",
            "Tara\tB-STREET_NAME\n",
            "Court\tI-STREET_NAME\n",
            "Adult\tO\n",
            "Sign\tO\n",
            "##ature\tO\n",
            "Re\tO\n",
            "##quire\tO\n",
            "##d\tO\n",
            "Lakes\tB-CITY\n",
            "##ide\t I-CITY\n",
            ",\tO\n",
            "NE\tB-STATE_ABBREVIATION\n",
            "69\tB-POSTAL_CODE\n",
            "##35\tI-POSTAL_CODE\n",
            "##1\tI-POSTAL_CODE\n",
            "-\tO\n",
            "114\tB-PLUS_4\n",
            "##6\tI-PLUS_4\n",
            "[SEP]\t-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## DO NOT USE\n",
        "\n",
        "def tokenize_fn(batch):\n",
        "    # Tokenize the input batch\n",
        "    tokenized_inputs = tokenizer(batch['tokens'], truncation=True, is_split_into_words=True, padding=\"max_length\")\n",
        "\n",
        "    # Extract the labels batch from the input batch\n",
        "    labels_batch = batch['ner_tags']\n",
        "\n",
        "    \"\"\"   # Initialize a list to store aligned targets for each example in the batch\n",
        "    aligned_targets_batch = []\n",
        "\n",
        "    # Iterate through each example and align the labels\n",
        "    for i, labels in enumerate(labels_batch):\n",
        "        # Extract the word_ids for the current example\n",
        "        word_ids = tokenized_inputs.word_ids(i)\n",
        "\n",
        "        # Use the align_target function to align the labels\n",
        "        aligned_targets_batch.append(align_target(labels, word_ids)) \"\"\"\n",
        "\n",
        "    # Add the aligned labels to the tokenized inputs under the key \"labels\"\n",
        "    tokenized_inputs[\"labels\"] = labels_batch\n",
        "\n",
        "    # Return the tokenized inputs, including aligned labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "Ts49in847ZBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = address_ner_dataset.map(tokenize_and_align_labels, batched=True, remove_columns=address_ner_dataset['train'].column_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "21cdc95f665f4836aa09eecfa1897eeb",
            "2e15f06c6ae849f89c386319dc885e8a",
            "32b9c24996b54fffa002d7dbca4459e7",
            "2f51b2826f5947ae92f071fd4ee5a3a8",
            "9ef7aa5f53a74aeab08d010499fdd988",
            "7f2f1e57fe6e4e75a0fe73976bad4411",
            "a8f3dc40457e487ba1b5955e558320a5",
            "16b7266f9b194f1b823db2ff966a6859",
            "c2fe0c2624d04294bc5ffc73398ca689",
            "f22f443f00624ece819fe0ae19360668",
            "092cf0dfde274facbd841202107fcf68"
          ]
        },
        "id": "Gqm17e-d7iCn",
        "outputId": "d81a6d90-8c25-462c-bda8-31d22a01a58d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/150000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21cdc95f665f4836aa09eecfa1897eeb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "# Create a DataCollatorForTokenClassification object\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "print(tokenized_dataset['train'])\n",
        "# Testing data using the data collator\n",
        "batch = data_collator([tokenized_dataset['train'][i] for i in range(1)])\n",
        "\n",
        "# Display the resulting batch\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MLsH5auMC4qU",
        "outputId": "ed8e2a2b-3ff7-42fd-fc7b-bbddae07ac35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 1350000\n",
            "})\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101, 17070,  4328,  7151, 17389,  2078,  4464, 10225,  2457,  4639,\n",
              "          8085,  3223, 28701,  1010, 11265,  6353, 19481,  2487,  1011, 12457,\n",
              "          2575,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "             0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[-100,    1,    1,    2,    2,    2,    3,    5,    6,    0,    0,    0,\n",
              "           11,    0,   13,   19,   19,   19,    0,   15,   15, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
              "         -100, -100, -100, -100, -100, -100, -100, -100]])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the seqeval library for evaluating sequence tasks\n",
        "!pip install seqeval ;\n",
        "!pip install evaluate ;"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MObhKhIQHUlh",
        "outputId": "527cdcd2-192b-44c6-e877-3757de6508fc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the seqeval metric from Hugging Face's datasets library\n",
        "import evaluate\n",
        "\n",
        "# Load the seqeval metric which can evaluate NER and other sequence tasks\n",
        "metric = evaluate.load(\"seqeval\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6WuheeVwJE3M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Function to compute evaluation metrics from model logits and true labels\n",
        "def compute_metrics(logits_and_labels):\n",
        "\n",
        "  # Unpack the logits and labels\n",
        "  logits, labels = logits_and_labels\n",
        "\n",
        "  # Get predictions from the logits\n",
        "  predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "  # Remove ignored index (special tokens)\n",
        "  str_labels = [\n",
        "    [label_names[t] for t in label if t!=-100] for label in labels\n",
        "  ]\n",
        "\n",
        "  str_preds = [\n",
        "    [label_names[p] for (p, t) in zip(prediction, label) if t != -100]\n",
        "    for prediction, label in zip(predictions, labels)\n",
        "  ]\n",
        "\n",
        "  # Compute metrics\n",
        "  results = metric.compute(predictions=str_preds, references=str_labels)\n",
        "\n",
        "  # Extract key metrics\n",
        "  return {\n",
        "    \"precision\": results[\"overall_precision\"],\n",
        "    \"recall\": results[\"overall_recall\"],\n",
        "    \"f1\": results[\"overall_f1\"],\n",
        "    \"accuracy\": results[\"overall_accuracy\"]\n",
        "  }"
      ],
      "metadata": {
        "id": "SXO-yQJ6HZrj"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create mapping from label ID to label string name\n",
        "id2label = {k: v for k, v in enumerate(label_names)}\n",
        "\n",
        "# Create reverse mapping from label name to label ID\n",
        "label2id = {v: k for k, v in enumerate(label_names)}\n",
        "\n",
        "print(id2label , '\\n--------------------\\n' , label2id)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBlpDC66JuJS",
        "outputId": "5d6e885a-e6da-4f06-ed01-ae21b5b18cbd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'B-NAME', 2: 'I-NAME', 3: 'B-STREET_NUMBER', 4: 'I-STREET_NUMBER', 5: 'B-STREET_NAME', 6: 'I-STREET_NAME', 7: 'B-UNIT_NUMBER', 8: 'I-UNIT_NUMBER', 9: 'B-UNIT_DESIGNATOR', 10: 'I-UNIT_DESIGNATOR', 11: 'B-CITY', 12: 'I-CITY', 13: 'B-STATE_ABBREVIATION', 14: 'I-STATE_ABBREVIATION', 15: 'B-PLUS_4', 16: 'I-PLUS_4', 17: 'B-STATE_NAME', 18: 'I-STATE_NAME', 19: 'B-POSTAL_CODE', 20: 'I-POSTAL_CODE', 21: 'B-TRACKING_NUMBER', 22: 'I-TRACKING_NUMBER'} \n",
            "--------------------\n",
            " {'O': 0, 'B-NAME': 1, 'I-NAME': 2, 'B-STREET_NUMBER': 3, 'I-STREET_NUMBER': 4, 'B-STREET_NAME': 5, 'I-STREET_NAME': 6, 'B-UNIT_NUMBER': 7, 'I-UNIT_NUMBER': 8, 'B-UNIT_DESIGNATOR': 9, 'I-UNIT_DESIGNATOR': 10, 'B-CITY': 11, 'I-CITY': 12, 'B-STATE_ABBREVIATION': 13, 'I-STATE_ABBREVIATION': 14, 'B-PLUS_4': 15, 'I-PLUS_4': 16, 'B-STATE_NAME': 17, 'I-STATE_NAME': 18, 'B-POSTAL_CODE': 19, 'I-POSTAL_CODE': 20, 'B-TRACKING_NUMBER': 21, 'I-TRACKING_NUMBER': 22}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pretrained token classification model from Transformers\n",
        "from transformers import AutoModelForTokenClassification\n",
        "\n",
        "# Initialize model object with pretrained weights\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "  checkpoint,\n",
        "  num_labels=len(label_names),\n",
        "  # Pass in label mappings\n",
        "  id2label=id2label,\n",
        "  label2id=label2id,\n",
        "  ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ataPvwEUvx7g",
        "outputId": "347cf9e0-bc2d-48c6-f962-269b837fd496"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at issifuamajeed/distilbert-base-uncased-finetuned-ner and are newly initialized because the shapes did not match:\n",
            "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([23]) in the model instantiated\n",
            "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([23, 768]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure training arguments using TrainigArguments class\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  # Location to save fine-tuned model\n",
        "  output_dir = \"address_parser_fine_tuned_model\",\n",
        "\n",
        "  # Evaluate each epoch\n",
        "  evaluation_strategy = \"epoch\",\n",
        "\n",
        "  # Learning rate for Adam optimizer\n",
        "  learning_rate =  1e-4 , #2e-05, #1e-4 - very good result.\n",
        "\n",
        "  # Batch sizes for training and evaluation\n",
        "  per_device_train_batch_size = 16,\n",
        "  per_device_eval_batch_size = 16,\n",
        "\n",
        "  # Number of training epochs\n",
        "  num_train_epochs = 4,\n",
        "\n",
        "  # L2 weight decay regularization\n",
        "  weight_decay = 0.01 # 0.01  1e-5\n",
        ")"
      ],
      "metadata": {
        "id": "1JNh6bCswxVr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9e2556b-0660-4389-9ce5-57ff0897d5a5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Trainer object for model training\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "  # Model to train\n",
        "  model=model,\n",
        "\n",
        "  # Training arguments\n",
        "  args=training_args,\n",
        "\n",
        "  # Training and validation datasets\n",
        "  train_dataset=tokenized_dataset[\"train\"].shuffle(seed=42).select(range(300)),\n",
        "  eval_dataset=tokenized_dataset[\"test\"].shuffle(seed=42).select(range(300)),\n",
        "\n",
        "  # Tokenizer\n",
        "  tokenizer=tokenizer,\n",
        "\n",
        "  # Custom metric function\n",
        "  compute_metrics=compute_metrics,\n",
        "\n",
        "  # Data collator\n",
        "  #data_collator=data_collator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EbwmrjTw_Ig",
        "outputId": "926cfa8f-9bd4-4598-8b20-8c339334e852"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-432653dc1cd4>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "ECtJx4f_2TpM",
        "outputId": "2a48b8ed-0586-4e5d-c3e9-a5810c220975"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjohnbarret25\u001b[0m (\u001b[33mjohnbarret25-eriss\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250206_015114-29tzbcsl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/johnbarret25-eriss/huggingface/runs/29tzbcsl' target=\"_blank\">address_parser_fine_tuned_model</a></strong> to <a href='https://wandb.ai/johnbarret25-eriss/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/johnbarret25-eriss/huggingface' target=\"_blank\">https://wandb.ai/johnbarret25-eriss/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/johnbarret25-eriss/huggingface/runs/29tzbcsl' target=\"_blank\">https://wandb.ai/johnbarret25-eriss/huggingface/runs/29tzbcsl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [76/76 1:23:23, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.239635</td>\n",
              "      <td>0.938225</td>\n",
              "      <td>0.943425</td>\n",
              "      <td>0.940818</td>\n",
              "      <td>0.951156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.085451</td>\n",
              "      <td>0.971418</td>\n",
              "      <td>0.980887</td>\n",
              "      <td>0.976129</td>\n",
              "      <td>0.981224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.050362</td>\n",
              "      <td>0.987226</td>\n",
              "      <td>0.989679</td>\n",
              "      <td>0.988451</td>\n",
              "      <td>0.989660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.046179</td>\n",
              "      <td>0.988948</td>\n",
              "      <td>0.991972</td>\n",
              "      <td>0.990458</td>\n",
              "      <td>0.991020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=76, training_loss=0.3598196882950632, metrics={'train_runtime': 5070.683, 'train_samples_per_second': 0.237, 'train_steps_per_second': 0.015, 'total_flos': 156843251712000.0, 'train_loss': 0.3598196882950632, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWu-sqt_mXiE",
        "outputId": "21bb7348-a7d6-4018-978a-49f49996d21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = 'address_parser_fine_tuned_model.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\"\n",
        "#torch.save(model.state_dict(), path)\n",
        "trainer.save_model(path)"
      ],
      "metadata": {
        "id": "oRbRtMMZmhfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "trainer.save_model('https://drive.google.com/drive/u/0/folders/1Tv0NPBLHA4rWoIKL71KtNlhc8NsQfCOu/address_parser_fine_tuned_model')"
      ],
      "metadata": {
        "id": "wx96iO7YROpO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('address_parser_fine_tuned_model')"
      ],
      "metadata": {
        "id": "xas0NJ9GADrk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "ner = pipeline(\n",
        "    'token-classification',\n",
        "    model = 'address_parser_fine_tuned_model',\n",
        "    aggregation_strategy = 'simple' ,\n",
        "    device = 0\n",
        ")"
      ],
      "metadata": {
        "id": "3GPYrcXNAKi5",
        "outputId": "23704df3-78bf-4e61-d705-c5ec08ddaa62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ner('1001 BRECKENRIDGE LN, ST MATTHEWS, KY 40207\\-0000')"
      ],
      "metadata": {
        "id": "_SdmMuESAOrN",
        "outputId": "b7cc693c-6d65-4610-b9e0-f13f83290811",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity_group': 'STREET_NUMBER',\n",
              "  'score': 0.9704549,\n",
              "  'word': '100',\n",
              "  'start': 0,\n",
              "  'end': 3},\n",
              " {'entity_group': 'STREET_NUMBER',\n",
              "  'score': 0.9789489,\n",
              "  'word': '##1',\n",
              "  'start': 3,\n",
              "  'end': 4},\n",
              " {'entity_group': 'STREET_NAME',\n",
              "  'score': 0.98494256,\n",
              "  'word': 'br',\n",
              "  'start': 5,\n",
              "  'end': 7},\n",
              " {'entity_group': 'STREET_NAME',\n",
              "  'score': 0.98243976,\n",
              "  'word': '##eck',\n",
              "  'start': 7,\n",
              "  'end': 10},\n",
              " {'entity_group': 'STREET_NAME',\n",
              "  'score': 0.9822243,\n",
              "  'word': '##en',\n",
              "  'start': 10,\n",
              "  'end': 12},\n",
              " {'entity_group': 'STREET_NAME',\n",
              "  'score': 0.9251567,\n",
              "  'word': '##ridge l',\n",
              "  'start': 12,\n",
              "  'end': 19},\n",
              " {'entity_group': 'UNIT_DESIGNATOR',\n",
              "  'score': 0.48929447,\n",
              "  'word': '##n',\n",
              "  'start': 19,\n",
              "  'end': 20},\n",
              " {'entity_group': 'CITY',\n",
              "  'score': 0.9702918,\n",
              "  'word': 'st matthews',\n",
              "  'start': 22,\n",
              "  'end': 33},\n",
              " {'entity_group': 'STATE_ABBREVIATION',\n",
              "  'score': 0.9750769,\n",
              "  'word': 'ky',\n",
              "  'start': 35,\n",
              "  'end': 37},\n",
              " {'entity_group': 'POSTAL_CODE',\n",
              "  'score': 0.9952872,\n",
              "  'word': '402',\n",
              "  'start': 38,\n",
              "  'end': 41},\n",
              " {'entity_group': 'POSTAL_CODE',\n",
              "  'score': 0.99515706,\n",
              "  'word': '##0',\n",
              "  'start': 41,\n",
              "  'end': 42},\n",
              " {'entity_group': 'POSTAL_CODE',\n",
              "  'score': 0.99531245,\n",
              "  'word': '##7',\n",
              "  'start': 42,\n",
              "  'end': 43},\n",
              " {'entity_group': 'PLUS_4',\n",
              "  'score': 0.98982555,\n",
              "  'word': '000',\n",
              "  'start': 45,\n",
              "  'end': 48},\n",
              " {'entity_group': 'PLUS_4',\n",
              "  'score': 0.9911765,\n",
              "  'word': '##0',\n",
              "  'start': 48,\n",
              "  'end': 49}]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Using pretrained models (PyTorch)",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "21cdc95f665f4836aa09eecfa1897eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e15f06c6ae849f89c386319dc885e8a",
              "IPY_MODEL_32b9c24996b54fffa002d7dbca4459e7",
              "IPY_MODEL_2f51b2826f5947ae92f071fd4ee5a3a8"
            ],
            "layout": "IPY_MODEL_9ef7aa5f53a74aeab08d010499fdd988"
          }
        },
        "2e15f06c6ae849f89c386319dc885e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f2f1e57fe6e4e75a0fe73976bad4411",
            "placeholder": "​",
            "style": "IPY_MODEL_a8f3dc40457e487ba1b5955e558320a5",
            "value": "Map: 100%"
          }
        },
        "32b9c24996b54fffa002d7dbca4459e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16b7266f9b194f1b823db2ff966a6859",
            "max": 150000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c2fe0c2624d04294bc5ffc73398ca689",
            "value": 150000
          }
        },
        "2f51b2826f5947ae92f071fd4ee5a3a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f22f443f00624ece819fe0ae19360668",
            "placeholder": "​",
            "style": "IPY_MODEL_092cf0dfde274facbd841202107fcf68",
            "value": " 150000/150000 [01:31&lt;00:00, 1894.08 examples/s]"
          }
        },
        "9ef7aa5f53a74aeab08d010499fdd988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f2f1e57fe6e4e75a0fe73976bad4411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8f3dc40457e487ba1b5955e558320a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16b7266f9b194f1b823db2ff966a6859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2fe0c2624d04294bc5ffc73398ca689": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f22f443f00624ece819fe0ae19360668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092cf0dfde274facbd841202107fcf68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}